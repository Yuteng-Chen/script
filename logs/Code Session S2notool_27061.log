Job ID: 27061
Running on node: 474Y574
Date: Mon Feb  2 09:09:55 PM +08 2026
âœ… çŽ¯å¢ƒå·²æ¿€æ´»: /scratch/prj0000000262-bucket/ocr/ec/env/bin/activate
>>> [1/3] å°è¯•è¿›å…¥é¡¹ç›®ç›®å½•: /scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest
âœ… æˆåŠŸè¿›å…¥: /scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest

>>> [2/3] åŽå°å¯åŠ¨ CLIP Server...
CLIP Server å¯åŠ¨ä¸­ (PID: 2402764)
æ—¥å¿—è·¯å¾„: /scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/clip_as_service/server/clip_server.log
ç­‰å¾… CLIP Server å¯åŠ¨.........................
âœ… CLIP Server å¯åŠ¨æˆåŠŸï¼
CLIP Server çŠ¶æ€æ­£å¸¸ã€‚

>>> [3/3] å¼€å§‹è®­ç»ƒ (Stage 1)...
æ‰§è¡Œè„šæœ¬: /scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/scripts/train_stage_2_no_tool.sh
Local training mode: 8 GPUs on localhost:29500
INFO 02-02 21:10:51 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 02-02 21:10:51 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 02-02 21:10:51 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 02-02 21:10:51 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 02-02 21:10:51 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 02-02 21:10:51 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 02-02 21:10:51 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 02-02 21:10:51 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 02-02 21:10:51 [__init__.py:239] Automatically detected platform cuda.
INFO 02-02 21:10:51 [__init__.py:239] Automatically detected platform cuda.
INFO 02-02 21:10:51 [__init__.py:239] Automatically detected platform cuda.
INFO 02-02 21:10:51 [__init__.py:239] Automatically detected platform cuda.
INFO 02-02 21:10:51 [__init__.py:239] Automatically detected platform cuda.
INFO 02-02 21:10:51 [__init__.py:239] Automatically detected platform cuda.
INFO 02-02 21:10:51 [__init__.py:239] Automatically detected platform cuda.
INFO 02-02 21:10:51 [__init__.py:239] Automatically detected platform cuda.
[2026-02-02 21:10:56,638] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2026-02-02 21:10:56,642] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2026-02-02 21:10:56,653] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2026-02-02 21:10:56,655] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2026-02-02 21:10:56,659] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2026-02-02 21:10:56,661] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2026-02-02 21:10:56,668] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2026-02-02 21:10:56,669] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.


[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.


[93m [WARNING] [0m async_io: please install the libaio-dev package with apt[93m [WARNING] [0m async_io: please install the libaio-dev package with apt

[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.[93m [WARNING] [0m async_io: please install the libaio-dev package with apt[93m [WARNING] [0m async_io: please install the libaio-dev package with apt[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.



[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.


[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[2026-02-02 21:10:57,848] [INFO] [comm.py:637:init_distributed] cdb=None
[2026-02-02 21:10:57,848] [INFO] [comm.py:637:init_distributed] cdb=None
[2026-02-02 21:10:57,848] [INFO] [comm.py:637:init_distributed] cdb=None
[2026-02-02 21:10:57,848] [INFO] [comm.py:637:init_distributed] cdb=None
[2026-02-02 21:10:57,848] [INFO] [comm.py:637:init_distributed] cdb=None
[2026-02-02 21:10:57,848] [INFO] [comm.py:637:init_distributed] cdb=None
[2026-02-02 21:10:57,848] [INFO] [comm.py:637:init_distributed] cdb=None
[2026-02-02 21:10:57,848] [INFO] [comm.py:637:init_distributed] cdb=None
[DEBUG] Using default reward weights: [1.0, 0.5, 0.2]
Rank 0:  System prompt: You are a helpful video assistant.
# Tools

You may call one or more functions to assist with the user query.

You are provided with function signatures within <tools></tools> XML tags:
<tools>
{"type": "function", "function": {"name": "seek_video_frames", "description": "Search and select video frames according to textual query and temporal window. Time is in seconds.", "parameters": {"type": "object", "properties": {"query": {"type": "string", "description": "The query is used to describe the object, scene, or event of interest in the video thoroughly and clearly. "}, "start_time": {"type": "number", "description": "Start time of the segment of interest. "}, "end_time": {"type": "number", "description": "End time of the segment of interest. "}, "num_frames": {"type": "integer", "description": "Number of frames to sample (maximum 8). Default is 8."}}, "required": ["query"]}}}
</tools>

For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:
<tool_call>
{"name": <function-name>, "arguments": <args-json-object>}
</tool_call>
Rank 0:  Append time instruction: False
Rank 0:  Video kwargs: {'total_pixels': 8028160, 'min_pixels': 3136, 'max_pixels': 200704, 'max_frames': 700}
Rank 0:  Cache video kwargs: {'max_frames': 2048, 'fps': 2, 'min_pixels': 25088, 'max_pixels': 200704, 'total_pixels': 411041792}
Rank 0:  Loading /scratch/prj0000000262-bucket/ocr/ec/jsonfolder/COT_Video-R1_60/Video-R1-30K_grpo_ready_for_train_cyt.json with random:2000 sampling strategy
[DEBUG] Using default reward weights: [1.0, 0.5, 0.2]
[DEBUG] Using default reward weights: [1.0, 0.5, 0.2]
[DEBUG] Using default reward weights: [1.0, 0.5, 0.2]
[DEBUG] Using default reward weights: [1.0, 0.5, 0.2]
[DEBUG] Using default reward weights: [1.0, 0.5, 0.2]
[DEBUG] Using default reward weights: [1.0, 0.5, 0.2]
[DEBUG] Using default reward weights: [1.0, 0.5, 0.2]
Rank 0:  Loaded 2000 samples from /scratch/prj0000000262-bucket/ocr/ec/jsonfolder/COT_Video-R1_60/Video-R1-30K_grpo_ready_for_train_cyt.json
Rank 0:  Loading /scratch/prj0000000262-bucket/ocr/ec/jsonfolder/panda_70m_cleaned_indexed_cyt_panda300p.json with random:8000 sampling strategy
Rank 0:  Loaded 8000 samples from /scratch/prj0000000262-bucket/ocr/ec/jsonfolder/panda_70m_cleaned_indexed_cyt_panda300p.json
Rank 0:  Loaded 10000 samples from ['/scratch/prj0000000262-bucket/ocr/ec/jsonfolder/COT_Video-R1_60/Video-R1-30K_grpo_ready_for_train_cyt.json', '/scratch/prj0000000262-bucket/ocr/ec/jsonfolder/panda_70m_cleaned_indexed_cyt_panda300p.json']
Rank 0:  Loaded 10000 samples from configs/dataset.yaml
Rank 0:  Formatting inputs...Skip in lazy mode
Rank 0:  Dataset modalities status: defaultdict(<class 'int'>, {'video': 10000})
Rank 0:  Dataset template: <function make_prompt at 0x1550e1051800>
[2026-02-02 21:11:05,481] [INFO] [partition_parameters.py:345:__exit__] finished initializing model - num_params = 729, num_elems = 8.29B
[2026-02-02 21:11:18,934] [INFO] [partition_parameters.py:345:__exit__] finished initializing model - num_params = 1458, num_elems = 16.58B
INFO 02-02 21:11:32 [config.py:717] This model supports multiple tasks: {'generate', 'classify', 'score', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 02-02 21:11:32 [config.py:1729] Disabling V1 multiprocessing for external launcher.
INFO 02-02 21:11:32 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=16384.
INFO 02-02 21:11:33 [config.py:717] This model supports multiple tasks: {'score', 'classify', 'reward', 'embed', 'generate'}. Defaulting to 'generate'.
INFO 02-02 21:11:33 [config.py:1729] Disabling V1 multiprocessing for external launcher.
INFO 02-02 21:11:33 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=16384.
INFO 02-02 21:11:33 [config.py:717] This model supports multiple tasks: {'generate', 'reward', 'score', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 02-02 21:11:33 [config.py:1729] Disabling V1 multiprocessing for external launcher.
INFO 02-02 21:11:33 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=16384.
INFO 02-02 21:11:33 [config.py:717] This model supports multiple tasks: {'reward', 'score', 'generate', 'embed', 'classify'}. Defaulting to 'generate'.
INFO 02-02 21:11:33 [config.py:1729] Disabling V1 multiprocessing for external launcher.
INFO 02-02 21:11:33 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=16384.
INFO 02-02 21:11:33 [config.py:717] This model supports multiple tasks: {'classify', 'reward', 'embed', 'generate', 'score'}. Defaulting to 'generate'.
INFO 02-02 21:11:33 [config.py:1729] Disabling V1 multiprocessing for external launcher.
INFO 02-02 21:11:33 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=16384.
INFO 02-02 21:11:33 [config.py:717] This model supports multiple tasks: {'embed', 'generate', 'reward', 'classify', 'score'}. Defaulting to 'generate'.
INFO 02-02 21:11:33 [config.py:1729] Disabling V1 multiprocessing for external launcher.
INFO 02-02 21:11:33 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=16384.
INFO 02-02 21:11:33 [config.py:717] This model supports multiple tasks: {'generate', 'classify', 'score', 'embed', 'reward'}. Defaulting to 'generate'.
INFO 02-02 21:11:33 [config.py:1729] Disabling V1 multiprocessing for external launcher.
INFO 02-02 21:11:33 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=16384.
INFO 02-02 21:11:33 [config.py:717] This model supports multiple tasks: {'reward', 'embed', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
INFO 02-02 21:11:33 [config.py:1729] Disabling V1 multiprocessing for external launcher.
INFO 02-02 21:11:33 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=16384.
INFO 02-02 21:11:34 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200', speculative_config=None, tokenizer='/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=5, served_model_name=/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
INFO 02-02 21:11:34 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200', speculative_config=None, tokenizer='/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=3, served_model_name=/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
INFO 02-02 21:11:34 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200', speculative_config=None, tokenizer='/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=1, served_model_name=/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
INFO 02-02 21:11:34 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200', speculative_config=None, tokenizer='/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=7, served_model_name=/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
INFO 02-02 21:11:34 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200', speculative_config=None, tokenizer='/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=2, served_model_name=/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
INFO 02-02 21:11:34 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200', speculative_config=None, tokenizer='/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
INFO 02-02 21:11:34 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200', speculative_config=None, tokenizer='/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=6, served_model_name=/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
INFO 02-02 21:11:34 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200', speculative_config=None, tokenizer='/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=4, served_model_name=/scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
WARNING 02-02 21:11:34 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x15509e875490>
WARNING 02-02 21:11:34 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x1550cec9c410>
WARNING 02-02 21:11:34 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x1550a93c4b10>
WARNING 02-02 21:11:34 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x1550ce655f10>
WARNING 02-02 21:11:34 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x1550ce90de90>
WARNING 02-02 21:11:34 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x1550c3a22f90>
WARNING 02-02 21:11:34 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x15509ef52410>
WARNING 02-02 21:11:34 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x1550ce45c590>
INFO 02-02 21:11:35 [parallel_state.py:1004] rank 5 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 02-02 21:11:35 [parallel_state.py:1004] rank 6 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 02-02 21:11:35 [parallel_state.py:1004] rank 7 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 02-02 21:11:35 [parallel_state.py:1004] rank 3 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 02-02 21:11:35 [parallel_state.py:1004] rank 0 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 02-02 21:11:35 [parallel_state.py:1004] rank 2 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 02-02 21:11:35 [parallel_state.py:1004] rank 4 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 02-02 21:11:35 [parallel_state.py:1004] rank 1 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 02-02 21:11:35 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 02-02 21:11:35 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 02-02 21:11:35 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 02-02 21:11:35 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 02-02 21:11:35 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 02-02 21:11:35 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 02-02 21:11:35 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 02-02 21:11:35 [cuda.py:221] Using Flash Attention backend on V1 engine.
WARNING 02-02 21:11:39 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
INFO 02-02 21:11:39 [gpu_model_runner.py:1329] Starting to load model /scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200...
WARNING 02-02 21:11:39 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
INFO 02-02 21:11:39 [gpu_model_runner.py:1329] Starting to load model /scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200...
INFO 02-02 21:11:39 [config.py:3614] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512] is overridden by config [512, 384, 256, 128, 4, 2, 1, 392, 264, 136, 8, 400, 272, 144, 16, 408, 280, 152, 24, 416, 288, 160, 32, 424, 296, 168, 40, 432, 304, 176, 48, 440, 312, 184, 56, 448, 320, 192, 64, 456, 328, 200, 72, 464, 336, 208, 80, 472, 344, 216, 88, 120, 480, 352, 248, 224, 96, 488, 504, 360, 232, 104, 496, 368, 240, 112, 376]
INFO 02-02 21:11:39 [config.py:3614] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512] is overridden by config [512, 384, 256, 128, 4, 2, 1, 392, 264, 136, 8, 400, 272, 144, 16, 408, 280, 152, 24, 416, 288, 160, 32, 424, 296, 168, 40, 432, 304, 176, 48, 440, 312, 184, 56, 448, 320, 192, 64, 456, 328, 200, 72, 464, 336, 208, 80, 472, 344, 216, 88, 120, 480, 352, 248, 224, 96, 488, 504, 360, 232, 104, 496, 368, 240, 112, 376]
WARNING 02-02 21:11:39 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
INFO 02-02 21:11:39 [gpu_model_runner.py:1329] Starting to load model /scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200...
INFO 02-02 21:11:39 [config.py:3614] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512] is overridden by config [512, 384, 256, 128, 4, 2, 1, 392, 264, 136, 8, 400, 272, 144, 16, 408, 280, 152, 24, 416, 288, 160, 32, 424, 296, 168, 40, 432, 304, 176, 48, 440, 312, 184, 56, 448, 320, 192, 64, 456, 328, 200, 72, 464, 336, 208, 80, 472, 344, 216, 88, 120, 480, 352, 248, 224, 96, 488, 504, 360, 232, 104, 496, 368, 240, 112, 376]
WARNING 02-02 21:11:40 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
INFO 02-02 21:11:40 [gpu_model_runner.py:1329] Starting to load model /scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200...
WARNING 02-02 21:11:40 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
INFO 02-02 21:11:40 [gpu_model_runner.py:1329] Starting to load model /scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200...
WARNING 02-02 21:11:40 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
INFO 02-02 21:11:40 [gpu_model_runner.py:1329] Starting to load model /scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200...
WARNING 02-02 21:11:40 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
INFO 02-02 21:11:40 [gpu_model_runner.py:1329] Starting to load model /scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200...
INFO 02-02 21:11:40 [config.py:3614] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512] is overridden by config [512, 384, 256, 128, 4, 2, 1, 392, 264, 136, 8, 400, 272, 144, 16, 408, 280, 152, 24, 416, 288, 160, 32, 424, 296, 168, 40, 432, 304, 176, 48, 440, 312, 184, 56, 448, 320, 192, 64, 456, 328, 200, 72, 464, 336, 208, 80, 472, 344, 216, 88, 120, 480, 352, 248, 224, 96, 488, 504, 360, 232, 104, 496, 368, 240, 112, 376]
INFO 02-02 21:11:40 [config.py:3614] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512] is overridden by config [512, 384, 256, 128, 4, 2, 1, 392, 264, 136, 8, 400, 272, 144, 16, 408, 280, 152, 24, 416, 288, 160, 32, 424, 296, 168, 40, 432, 304, 176, 48, 440, 312, 184, 56, 448, 320, 192, 64, 456, 328, 200, 72, 464, 336, 208, 80, 472, 344, 216, 88, 120, 480, 352, 248, 224, 96, 488, 504, 360, 232, 104, 496, 368, 240, 112, 376]
INFO 02-02 21:11:40 [config.py:3614] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512] is overridden by config [512, 384, 256, 128, 4, 2, 1, 392, 264, 136, 8, 400, 272, 144, 16, 408, 280, 152, 24, 416, 288, 160, 32, 424, 296, 168, 40, 432, 304, 176, 48, 440, 312, 184, 56, 448, 320, 192, 64, 456, 328, 200, 72, 464, 336, 208, 80, 472, 344, 216, 88, 120, 480, 352, 248, 224, 96, 488, 504, 360, 232, 104, 496, 368, 240, 112, 376]
INFO 02-02 21:11:40 [config.py:3614] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512] is overridden by config [512, 384, 256, 128, 4, 2, 1, 392, 264, 136, 8, 400, 272, 144, 16, 408, 280, 152, 24, 416, 288, 160, 32, 424, 296, 168, 40, 432, 304, 176, 48, 440, 312, 184, 56, 448, 320, 192, 64, 456, 328, 200, 72, 464, 336, 208, 80, 472, 344, 216, 88, 120, 480, 352, 248, 224, 96, 488, 504, 360, 232, 104, 496, 368, 240, 112, 376]
WARNING 02-02 21:11:41 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
INFO 02-02 21:11:41 [gpu_model_runner.py:1329] Starting to load model /scratch/prj0000000262-bucket/ocr/ec/TimeSearch-R_latest/experiment/check600_v_1_video-r1_stage1_test_cyt/2026-01-28-01/Qwen2.5-VL-1200...
INFO 02-02 21:11:41 [config.py:3614] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512] is overridden by config [512, 384, 256, 128, 4, 2, 1, 392, 264, 136, 8, 400, 272, 144, 16, 408, 280, 152, 24, 416, 288, 160, 32, 424, 296, 168, 40, 432, 304, 176, 48, 440, 312, 184, 56, 448, 320, 192, 64, 456, 328, 200, 72, 464, 336, 208, 80, 472, 344, 216, 88, 120, 480, 352, 248, 224, 96, 488, 504, 360, 232, 104, 496, 368, 240, 112, 376]
INFO 02-02 21:11:44 [loader.py:458] Loading weights took 3.91 seconds
INFO 02-02 21:11:44 [loader.py:458] Loading weights took 4.11 seconds
INFO 02-02 21:11:44 [loader.py:458] Loading weights took 4.11 seconds
INFO 02-02 21:11:44 [loader.py:458] Loading weights took 3.32 seconds
INFO 02-02 21:11:44 [gpu_model_runner.py:1347] Model loading took 15.5675 GiB and 4.276082 seconds
INFO 02-02 21:11:44 [gpu_model_runner.py:1347] Model loading took 15.5675 GiB and 4.533700 seconds
INFO 02-02 21:11:44 [gpu_model_runner.py:1347] Model loading took 15.5675 GiB and 4.566752 seconds
INFO 02-02 21:11:44 [gpu_model_runner.py:1347] Model loading took 15.5675 GiB and 4.349447 seconds
INFO 02-02 21:11:45 [loader.py:458] Loading weights took 3.74 seconds
INFO 02-02 21:11:45 [loader.py:458] Loading weights took 4.12 seconds
INFO 02-02 21:11:45 [loader.py:458] Loading weights took 4.32 seconds
INFO 02-02 21:11:45 [loader.py:458] Loading weights took 4.23 seconds
INFO 02-02 21:11:45 [gpu_model_runner.py:1620] Encoder cache will be initialized with a budget of 16384 tokens, and profiled with 1 image items of the maximum feature size.
INFO 02-02 21:11:45 [gpu_model_runner.py:1620] Encoder cache will be initialized with a budget of 16384 tokens, and profiled with 1 image items of the maximum feature size.
INFO 02-02 21:11:45 [gpu_model_runner.py:1347] Model loading took 15.5675 GiB and 4.177087 seconds
INFO 02-02 21:11:45 [gpu_model_runner.py:1347] Model loading took 15.5675 GiB and 5.221018 seconds
INFO 02-02 21:11:45 [gpu_model_runner.py:1347] Model loading took 15.5675 GiB and 5.283287 seconds
INFO 02-02 21:11:45 [gpu_model_runner.py:1347] Model loading took 15.5675 GiB and 5.349215 seconds
INFO 02-02 21:11:45 [gpu_model_runner.py:1620] Encoder cache will be initialized with a budget of 16384 tokens, and profiled with 1 image items of the maximum feature size.
INFO 02-02 21:11:46 [gpu_model_runner.py:1620] Encoder cache will be initialized with a budget of 16384 tokens, and profiled with 1 image items of the maximum feature size.
INFO 02-02 21:11:46 [gpu_model_runner.py:1620] Encoder cache will be initialized with a budget of 16384 tokens, and profiled with 1 image items of the maximum feature size.
INFO 02-02 21:11:47 [gpu_model_runner.py:1620] Encoder cache will be initialized with a budget of 16384 tokens, and profiled with 1 image items of the maximum feature size.
INFO 02-02 21:11:47 [gpu_model_runner.py:1620] Encoder cache will be initialized with a budget of 16384 tokens, and profiled with 1 image items of the maximum feature size.
INFO 02-02 21:11:47 [gpu_model_runner.py:1620] Encoder cache will be initialized with a budget of 16384 tokens, and profiled with 1 image items of the maximum feature size.
INFO 02-02 21:11:53 [backends.py:420] Using cache directory: /home/users/astar/simt/wanfy/.cache/vllm/torch_compile_cache/09eca0285d/rank_5_0 for vLLM's torch.compile
INFO 02-02 21:11:53 [backends.py:420] Using cache directory: /home/users/astar/simt/wanfy/.cache/vllm/torch_compile_cache/09eca0285d/rank_7_0 for vLLM's torch.compile
INFO 02-02 21:11:53 [backends.py:420] Using cache directory: /home/users/astar/simt/wanfy/.cache/vllm/torch_compile_cache/09eca0285d/rank_1_0 for vLLM's torch.compile
INFO 02-02 21:11:53 [backends.py:420] Using cache directory: /home/users/astar/simt/wanfy/.cache/vllm/torch_compile_cache/09eca0285d/rank_6_0 for vLLM's torch.compile
INFO 02-02 21:11:53 [backends.py:420] Using cache directory: /home/users/astar/simt/wanfy/.cache/vllm/torch_compile_cache/09eca0285d/rank_3_0 for vLLM's torch.compile
INFO 02-02 21:11:53 [backends.py:420] Using cache directory: /home/users/astar/simt/wanfy/.cache/vllm/torch_compile_cache/09eca0285d/rank_2_0 for vLLM's torch.compile
INFO 02-02 21:11:53 [backends.py:430] Dynamo bytecode transform time: 5.00 s
INFO 02-02 21:11:53 [backends.py:430] Dynamo bytecode transform time: 5.62 s
INFO 02-02 21:11:53 [backends.py:430] Dynamo bytecode transform time: 5.72 s
INFO 02-02 21:11:53 [backends.py:430] Dynamo bytecode transform time: 5.51 s
INFO 02-02 21:11:53 [backends.py:430] Dynamo bytecode transform time: 5.72 s
INFO 02-02 21:11:53 [backends.py:430] Dynamo bytecode transform time: 5.35 s
INFO 02-02 21:11:54 [backends.py:420] Using cache directory: /home/users/astar/simt/wanfy/.cache/vllm/torch_compile_cache/09eca0285d/rank_0_0 for vLLM's torch.compile
INFO 02-02 21:11:54 [backends.py:430] Dynamo bytecode transform time: 5.33 s
INFO 02-02 21:11:54 [backends.py:420] Using cache directory: /home/users/astar/simt/wanfy/.cache/vllm/torch_compile_cache/09eca0285d/rank_4_0 for vLLM's torch.compile
INFO 02-02 21:11:54 [backends.py:430] Dynamo bytecode transform time: 5.34 s
INFO 02-02 21:11:57 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 3.846 s
INFO 02-02 21:11:57 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 3.810 s
INFO 02-02 21:11:58 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 3.889 s
INFO 02-02 21:11:58 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 3.738 s
INFO 02-02 21:11:58 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 4.149 s
INFO 02-02 21:11:58 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 4.198 s
INFO 02-02 21:11:58 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 3.891 s
INFO 02-02 21:11:58 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 4.306 s
INFO 02-02 21:11:58 [monitor.py:33] torch.compile takes 5.00 s in total
INFO 02-02 21:11:58 [monitor.py:33] torch.compile takes 5.35 s in total
INFO 02-02 21:11:58 [monitor.py:33] torch.compile takes 5.72 s in total
INFO 02-02 21:11:58 [monitor.py:33] torch.compile takes 5.34 s in total
INFO 02-02 21:11:59 [monitor.py:33] torch.compile takes 5.33 s in total
INFO 02-02 21:11:59 [monitor.py:33] torch.compile takes 5.51 s in total
INFO 02-02 21:11:59 [monitor.py:33] torch.compile takes 5.72 s in total
INFO 02-02 21:11:59 [monitor.py:33] torch.compile takes 5.62 s in total
INFO 02-02 21:12:00 [kv_cache_utils.py:634] GPU KV cache size: 335,344 tokens
INFO 02-02 21:12:00 [kv_cache_utils.py:634] GPU KV cache size: 335,344 tokens
INFO 02-02 21:12:00 [kv_cache_utils.py:634] GPU KV cache size: 335,344 tokens
INFO 02-02 21:12:00 [kv_cache_utils.py:634] GPU KV cache size: 335,344 tokens
INFO 02-02 21:12:00 [kv_cache_utils.py:637] Maximum concurrency for 40,000 tokens per request: 8.38x
INFO 02-02 21:12:00 [kv_cache_utils.py:637] Maximum concurrency for 40,000 tokens per request: 8.38x
INFO 02-02 21:12:00 [kv_cache_utils.py:637] Maximum concurrency for 40,000 tokens per request: 8.38x
INFO 02-02 21:12:00 [kv_cache_utils.py:637] Maximum concurrency for 40,000 tokens per request: 8.38x
INFO 02-02 21:12:00 [kv_cache_utils.py:634] GPU KV cache size: 335,344 tokens
INFO 02-02 21:12:00 [kv_cache_utils.py:634] GPU KV cache size: 335,344 tokens
INFO 02-02 21:12:00 [kv_cache_utils.py:637] Maximum concurrency for 40,000 tokens per request: 8.38x
INFO 02-02 21:12:00 [kv_cache_utils.py:637] Maximum concurrency for 40,000 tokens per request: 8.38x
INFO 02-02 21:12:00 [kv_cache_utils.py:634] GPU KV cache size: 335,344 tokens
INFO 02-02 21:12:00 [kv_cache_utils.py:634] GPU KV cache size: 335,344 tokens
INFO 02-02 21:12:00 [kv_cache_utils.py:637] Maximum concurrency for 40,000 tokens per request: 8.38x
INFO 02-02 21:12:00 [kv_cache_utils.py:637] Maximum concurrency for 40,000 tokens per request: 8.38x
INFO 02-02 21:12:33 [gpu_model_runner.py:1686] Graph capturing finished in 30 secs, took 0.56 GiB
INFO 02-02 21:12:33 [core.py:159] init engine (profile, create kv cache, warmup model) took 47.66 seconds
INFO 02-02 21:12:33 [gpu_model_runner.py:1686] Graph capturing finished in 31 secs, took 0.56 GiB
INFO 02-02 21:12:33 [core.py:159] init engine (profile, create kv cache, warmup model) took 48.03 seconds
INFO 02-02 21:12:36 [gpu_model_runner.py:1686] Graph capturing finished in 33 secs, took 0.56 GiB
INFO 02-02 21:12:36 [core.py:159] init engine (profile, create kv cache, warmup model) took 50.79 seconds
INFO 02-02 21:12:36 [gpu_model_runner.py:1686] Graph capturing finished in 33 secs, took 0.56 GiB
INFO 02-02 21:12:36 [core.py:159] init engine (profile, create kv cache, warmup model) took 52.30 seconds
INFO 02-02 21:12:37 [gpu_model_runner.py:1686] Graph capturing finished in 34 secs, took 0.56 GiB
INFO 02-02 21:12:37 [core.py:159] init engine (profile, create kv cache, warmup model) took 51.71 seconds
INFO 02-02 21:12:40 [gpu_model_runner.py:1686] Graph capturing finished in 38 secs, took 0.56 GiB
INFO 02-02 21:12:40 [core.py:159] init engine (profile, create kv cache, warmup model) took 55.96 seconds
INFO 02-02 21:12:40 [gpu_model_runner.py:1686] Graph capturing finished in 37 secs, took 0.56 GiB
INFO 02-02 21:12:40 [core.py:159] init engine (profile, create kv cache, warmup model) took 55.99 seconds
INFO 02-02 21:12:40 [gpu_model_runner.py:1686] Graph capturing finished in 38 secs, took 0.56 GiB
INFO 02-02 21:12:40 [core.py:159] init engine (profile, create kv cache, warmup model) took 55.96 seconds
[2026-02-02 21:12:41,740] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.5, git-hash=unknown, git-branch=unknown
[2026-02-02 21:12:41,753] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
ninja: no work to do.
Time to load cpu_adam op: 2.5602293014526367 seconds
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000001, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1
Time to load cpu_adam op: 2.5991740226745605 seconds
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000001, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1
ninja: no work to do.
Time to load cpu_adam op: 2.776841878890991 seconds
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000001, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1
Time to load cpu_adam op: 2.8502466678619385 seconds
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000001, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1
Time to load cpu_adam op: 2.8498754501342773 seconds
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000001, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1
[2026-02-02 21:12:46,113] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer
[2026-02-02 21:12:46,113] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
Time to load cpu_adam op: 2.854010581970215 seconds
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000001, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1
Time to load cpu_adam op: 2.852520227432251 seconds
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000001, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1
Time to load cpu_adam op: 2.8547122478485107 seconds
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000001, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1
[2026-02-02 21:12:46,145] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2026-02-02 21:12:46,145] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2026-02-02 21:12:46,145] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[2026-02-02 21:12:46,145] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[2026-02-02 21:12:46,590] [INFO] [utils.py:781:see_memory_usage] Stage 3 initialize beginning
[2026-02-02 21:12:46,591] [INFO] [utils.py:782:see_memory_usage] MA 33.68 GB         Max_MA 33.75 GB         CA 33.82 GB         Max_CA 34 GB 
[2026-02-02 21:12:46,591] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 156.78 GB, percent = 7.8%
[2026-02-02 21:12:46,593] [INFO] [stage3.py:130:__init__] Reduce bucket size 500,000,000
[2026-02-02 21:12:46,594] [INFO] [stage3.py:131:__init__] Prefetch bucket size 50,000,000
[2026-02-02 21:12:47,020] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2026-02-02 21:12:47,020] [INFO] [utils.py:782:see_memory_usage] MA 33.68 GB         Max_MA 33.68 GB         CA 33.82 GB         Max_CA 34 GB 
[2026-02-02 21:12:47,020] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 156.77 GB, percent = 7.8%
Parameter Offload: Total persistent parameters: 848896 in 368 params
[2026-02-02 21:12:47,475] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2026-02-02 21:12:47,475] [INFO] [utils.py:782:see_memory_usage] MA 33.68 GB         Max_MA 33.68 GB         CA 33.82 GB         Max_CA 34 GB 
[2026-02-02 21:12:47,476] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 156.78 GB, percent = 7.8%
[2026-02-02 21:12:47,918] [INFO] [utils.py:781:see_memory_usage] Before creating fp16 partitions
[2026-02-02 21:12:47,919] [INFO] [utils.py:782:see_memory_usage] MA 33.68 GB         Max_MA 33.68 GB         CA 33.82 GB         Max_CA 34 GB 
[2026-02-02 21:12:47,919] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 156.78 GB, percent = 7.8%
[2026-02-02 21:12:50,270] [INFO] [utils.py:781:see_memory_usage] After creating fp16 partitions: 1
[2026-02-02 21:12:50,271] [INFO] [utils.py:782:see_memory_usage] MA 33.68 GB         Max_MA 33.68 GB         CA 33.82 GB         Max_CA 34 GB 
[2026-02-02 21:12:50,271] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 199.87 GB, percent = 9.9%
[2026-02-02 21:12:50,709] [INFO] [utils.py:781:see_memory_usage] Before creating fp32 partitions
[2026-02-02 21:12:50,710] [INFO] [utils.py:782:see_memory_usage] MA 33.68 GB         Max_MA 33.68 GB         CA 33.82 GB         Max_CA 34 GB 
[2026-02-02 21:12:50,710] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 199.87 GB, percent = 9.9%
[2026-02-02 21:12:51,535] [INFO] [utils.py:781:see_memory_usage] After creating fp32 partitions
[2026-02-02 21:12:51,535] [INFO] [utils.py:782:see_memory_usage] MA 33.68 GB         Max_MA 33.68 GB         CA 33.82 GB         Max_CA 34 GB 
[2026-02-02 21:12:51,535] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 203.74 GB, percent = 10.1%
[2026-02-02 21:12:52,642] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[2026-02-02 21:12:52,642] [INFO] [utils.py:782:see_memory_usage] MA 33.68 GB         Max_MA 33.68 GB         CA 33.82 GB         Max_CA 34 GB 
[2026-02-02 21:12:52,642] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 260.26 GB, percent = 12.9%
[2026-02-02 21:12:55,911] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[2026-02-02 21:12:55,911] [INFO] [utils.py:782:see_memory_usage] MA 33.68 GB         Max_MA 33.68 GB         CA 33.82 GB         Max_CA 34 GB 
[2026-02-02 21:12:55,911] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 233.4 GB, percent = 11.6%
[2026-02-02 21:12:55,912] [INFO] [stage3.py:485:_setup_for_real_optimizer] optimizer state initialized
[2026-02-02 21:12:58,561] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[2026-02-02 21:12:58,561] [INFO] [utils.py:782:see_memory_usage] MA 34.61 GB         Max_MA 36.64 GB         CA 36.83 GB         Max_CA 37 GB 
[2026-02-02 21:12:58,561] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 253.0 GB, percent = 12.6%
[2026-02-02 21:12:58,561] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer_Stage3
[2026-02-02 21:12:58,562] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = None
[2026-02-02 21:12:58,562] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2026-02-02 21:12:58,562] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-06], mom=[[0.9, 0.999]]
[2026-02-02 21:12:58,563] [INFO] [config.py:997:print] DeepSpeedEngine configuration:
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   amp_enabled .................. False
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   amp_params ................... False
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   bfloat16_enabled ............. True
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   bfloat16_immediate_grad_update  False
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   checkpoint_parallel_write_pipeline  False
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   checkpoint_tag_validation_enabled  True
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   checkpoint_tag_validation_fail  False
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x154e47361f50>
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   communication_data_type ...... None
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   curriculum_enabled_legacy .... False
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   curriculum_params_legacy ..... False
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   data_efficiency_enabled ...... False
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   dataloader_drop_last ......... False
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   disable_allgather ............ False
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   dump_state ................... False
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   dynamic_loss_scale_args ...... None
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   eigenvalue_enabled ........... False
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   eigenvalue_gas_boundary_resolution  1
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   eigenvalue_layer_num ......... 0
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   eigenvalue_max_iter .......... 100
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   eigenvalue_stability ......... 1e-06
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   eigenvalue_tol ............... 0.01
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   eigenvalue_verbose ........... False
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   elasticity_enabled ........... False
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   fp16_auto_cast ............... None
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   fp16_enabled ................. False
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   fp16_master_weights_and_gradients  False
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   global_rank .................. 0
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   grad_accum_dtype ............. None
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   gradient_accumulation_steps .. 2
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   gradient_clipping ............ 1.0
[2026-02-02 21:12:58,564] [INFO] [config.py:1001:print]   gradient_predivide_factor .... 1.0
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   graph_harvesting ............. False
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   initial_dynamic_scale ........ 1
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   load_universal_checkpoint .... False
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   loss_scale ................... 1.0
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   memory_breakdown ............. False
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   mics_hierarchial_params_gather  False
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   mics_shard_size .............. -1
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   optimizer_legacy_fusion ...... False
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   optimizer_name ............... adamw
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   optimizer_params ............. {'lr': 1e-06, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.0}
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   pld_enabled .................. False
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   pld_params ................... False
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   prescale_gradients ........... False
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   scheduler_name ............... None
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   scheduler_params ............. None
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   seq_parallel_communication_data_type  torch.float32
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   sparse_attention ............. None
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   sparse_gradients_enabled ..... False
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   steps_per_print .............. inf
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   timers_config ................ enabled=True synchronized=True
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   train_batch_size ............. 16
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   train_micro_batch_size_per_gpu  1
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   use_data_before_expert_parallel_  False
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   use_node_local_storage ....... False
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   wall_clock_breakdown ......... False
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   weight_quantization_config ... None
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   world_size ................... 8
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   zero_allow_untested_optimizer  False
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=True) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   zero_enabled ................. True
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   zero_force_ds_cpu_optimizer .. True
[2026-02-02 21:12:58,565] [INFO] [config.py:1001:print]   zero_optimization_stage ...... 3
[2026-02-02 21:12:58,565] [INFO] [config.py:987:print_user_config]   json = {
    "fp16": {
        "enabled": false, 
        "loss_scale": 0, 
        "loss_scale_window": 1000, 
        "initial_scale_power": 16, 
        "hysteresis": 2, 
        "min_loss_scale": 1
    }, 
    "bf16": {
        "enabled": true
    }, 
    "optimizer": {
        "type": "AdamW", 
        "params": {
            "lr": 1e-06, 
            "betas": [0.9, 0.999], 
            "eps": 1e-08, 
            "weight_decay": 0.0
        }
    }, 
    "zero_optimization": {
        "stage": 3, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "offload_param": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "overlap_comm": true, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09, 
        "reduce_bucket_size": "auto", 
        "stage3_prefetch_bucket_size": "auto", 
        "stage3_param_persistence_threshold": "auto", 
        "stage3_max_live_parameters": 1.000000e+09, 
        "stage3_max_reuse_distance": 1.000000e+09, 
        "gather_16bit_weights_on_model_save": true
    }, 
    "gradient_accumulation_steps": 2, 
    "gradient_clipping": 1.0, 
    "train_batch_size": 16, 
    "train_micro_batch_size_per_gpu": 1, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "zero_optimization.reduce_bucket_size": 1.284506e+07, 
    "zero_optimization.stage3_param_persistence_threshold": 3.584000e+04, 
    "zero_optimization.stage3_prefetch_bucket_size": 1.156055e+07
}
Parameter Offload: Total persistent parameters: 848896 in 368 params
INFO 02-02 21:15:57 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:15:57 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:15:57 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:15:57 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:15:57 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:15:57 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:15:57 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:15:57 [block_pool.py:264] Successfully reset prefix cache
Failed to cast start_time: 3:46.000, set to 0.
Failed to cast end_time: 5:04.000, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0, 'grad_norm': 9.870835304260254, 'learning_rate': 9.999999013039592e-07, 'num_tokens': 167594.0, 'completions/mean_length': 100.3125, 'completions/min_length': 41.5, 'completions/max_length': 186.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 100.3125, 'completions/min_terminated_length': 41.5, 'completions/max_terminated_length': 186.0, 'rewards/multiturn_format_reward/mean': 0.9375, 'rewards/multiturn_format_reward/std': 0.1767766922712326, 'rewards/reflect_reward/mean': 0.3125, 'rewards/reflect_reward/std': 0.7019772529602051, 'rewards/reasoning_length_reward/mean': 0.8583333194255829, 'rewards/reasoning_length_reward/std': 0.19996866211295128, 'reward': 1.2654167413711548, 'reward_std': 0.4706679731607437, 'kl': 0.0, 'kl_visual': 0.0, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:18:03 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:18:03 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:18:03 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:18:03 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:18:03 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:18:03 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:18:03 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:18:03 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to cast start_time: 0:01, set to 0.
Failed to cast end_time: 1:30, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0, 'grad_norm': 9.564266204833984, 'learning_rate': 9.99999605215876e-07, 'num_tokens': 333939.0, 'completions/mean_length': 130.875, 'completions/min_length': 45.0, 'completions/max_length': 228.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 130.875, 'completions/min_terminated_length': 45.0, 'completions/max_terminated_length': 228.5, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.1875, 'rewards/reflect_reward/std': 0.7636376321315765, 'rewards/reasoning_length_reward/mean': 0.7864583432674408, 'rewards/reasoning_length_reward/std': 0.22258752584457397, 'reward': 1.2510416507720947, 'reward_std': 0.4040772169828415, 'kl': 0.0003948211669921875, 'kl_visual': 0.0005207061767578125, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:19:09 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:19:09 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:19:09 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:19:09 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:19:09 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:19:09 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:19:09 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:19:09 [block_pool.py:264] Successfully reset prefix cache
Failed to cast start_time: 03:40.000, set to 0.
Failed to cast end_time: 04:10.000, set to 0xffff.
Failed to cast start_time: 03:40.000, set to 0.
Failed to cast end_time: 04:10.000, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to cast start_time: 07:20, set to 0.
Failed to cast end_time: 07:50, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0, 'grad_norm': 7.411738872528076, 'learning_rate': 9.999991117358669e-07, 'num_tokens': 501571.0, 'completions/mean_length': 118.0, 'completions/min_length': 35.5, 'completions/max_length': 225.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 118.0, 'completions/min_terminated_length': 35.5, 'completions/max_terminated_length': 225.0, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.5, 'rewards/reflect_reward/std': 0.744023859500885, 'rewards/reasoning_length_reward/mean': 0.8458333015441895, 'rewards/reasoning_length_reward/std': 0.16984079033136368, 'reward': 1.4191666841506958, 'reward_std': 0.36404989659786224, 'kl': 0.0005140304565429688, 'kl_visual': 0.0006809234619140625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:20:28 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:20:28 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:20:28 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:20:28 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:20:28 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:20:28 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:20:28 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:20:28 [block_pool.py:264] Successfully reset prefix cache
Failed to cast start_time: 05:00, set to 0.
Failed to cast end_time: 05:30, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0, 'grad_norm': 25.538312911987305, 'learning_rate': 9.99998420864127e-07, 'num_tokens': 666374.0, 'completions/mean_length': 128.3125, 'completions/min_length': 22.5, 'completions/max_length': 227.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 128.3125, 'completions/min_terminated_length': 22.5, 'completions/max_terminated_length': 227.5, 'rewards/multiturn_format_reward/mean': 0.75, 'rewards/multiturn_format_reward/std': 0.4629100561141968, 'rewards/reflect_reward/mean': 0.5625, 'rewards/reflect_reward/std': 0.4172614812850952, 'rewards/reasoning_length_reward/mean': 0.8725694417953491, 'rewards/reasoning_length_reward/std': 0.16578201949596405, 'reward': 1.2057638466358185, 'reward_std': 0.6631604433059692, 'kl': 0.0010700225830078125, 'kl_visual': 0.0006799697875976562, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:21:34 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:21:34 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:21:34 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:21:34 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:21:34 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:21:34 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:21:34 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:21:34 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to cast start_time: 13.6s, set to 0.
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0, 'grad_norm': 5.539094924926758, 'learning_rate': 9.999975326009291e-07, 'num_tokens': 803884.0, 'completions/mean_length': 128.5625, 'completions/min_length': 72.0, 'completions/max_length': 220.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 128.5625, 'completions/min_terminated_length': 72.0, 'completions/max_terminated_length': 220.5, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.625, 'rewards/reflect_reward/std': 0.5487886220216751, 'rewards/reasoning_length_reward/mean': 0.8447916507720947, 'rewards/reasoning_length_reward/std': 0.19130200892686844, 'reward': 1.4814583659172058, 'reward_std': 0.2748487740755081, 'kl': 0.000690460205078125, 'kl_visual': 0.0005054473876953125, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:22:37 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:22:37 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:22:37 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:22:37 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:22:37 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:22:37 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:22:37 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:22:37 [block_pool.py:264] Successfully reset prefix cache
Failed to cast start_time: A) 05:20-05:50, set to 0.
Failed to cast end_time: D) 02:40-03:10, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0, 'grad_norm': 12.593202590942383, 'learning_rate': 9.999964469466235e-07, 'num_tokens': 943283.0, 'completions/mean_length': 122.25, 'completions/min_length': 42.0, 'completions/max_length': 171.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 122.25, 'completions/min_terminated_length': 42.0, 'completions/max_terminated_length': 171.0, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.4375, 'rewards/reflect_reward/std': 0.8349219858646393, 'rewards/reasoning_length_reward/mean': 0.8319444358348846, 'rewards/reasoning_length_reward/std': 0.20757047832012177, 'reward': 1.3851389288902283, 'reward_std': 0.41276486217975616, 'kl': 0.000988006591796875, 'kl_visual': 0.0007171630859375, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:23:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:23:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:23:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:23:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:23:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:23:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:23:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:23:39 [block_pool.py:264] Successfully reset prefix cache
Failed to cast start_time: 0.0s, set to 0.
Failed to cast end_time: 99.0s, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0, 'grad_norm': 15.280616760253906, 'learning_rate': 9.999951639016393e-07, 'num_tokens': 1110043.0, 'completions/mean_length': 125.8125, 'completions/min_length': 42.0, 'completions/max_length': 207.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 125.8125, 'completions/min_terminated_length': 42.0, 'completions/max_terminated_length': 207.0, 'rewards/multiturn_format_reward/mean': 0.75, 'rewards/multiturn_format_reward/std': 0.4355513006448746, 'rewards/reflect_reward/mean': 0.1875, 'rewards/reflect_reward/std': 0.8604641258716583, 'rewards/reasoning_length_reward/mean': 0.9104166924953461, 'rewards/reasoning_length_reward/std': 0.14362458139657974, 'reward': 1.0258333683013916, 'reward_std': 0.5483110994100571, 'kl': 0.00267791748046875, 'kl_visual': 0.000701904296875, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:24:46 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:24:46 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:24:46 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:24:46 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:24:46 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:24:46 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:24:46 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:24:46 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0, 'grad_norm': 9.352812767028809, 'learning_rate': 9.999936834664829e-07, 'num_tokens': 1261483.0, 'completions/mean_length': 131.4375, 'completions/min_length': 33.0, 'completions/max_length': 239.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 131.4375, 'completions/min_terminated_length': 33.0, 'completions/max_terminated_length': 239.0, 'rewards/multiturn_format_reward/mean': 0.9375, 'rewards/multiturn_format_reward/std': 0.1767766922712326, 'rewards/reflect_reward/mean': 0.375, 'rewards/reflect_reward/std': 0.7892734110355377, 'rewards/reasoning_length_reward/mean': 0.7840277850627899, 'rewards/reasoning_length_reward/std': 0.21648238599300385, 'reward': 1.2818055152893066, 'reward_std': 0.4714474231004715, 'kl': 0.001678466796875, 'kl_visual': 0.001117706298828125, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:25:51 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:25:51 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:25:51 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:25:51 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:25:51 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:25:51 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:25:51 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:25:51 [block_pool.py:264] Successfully reset prefix cache
Failed to cast start_time: 01:20, set to 0.
Failed to cast end_time: 01:50, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to call tool function: fn_name='unknown', fn_args={}, got err Unknown function name: unknown, duration: 714.25
Failed to call tool function: fn_name='unknown', fn_args={}, got err Unknown function name: unknown, duration: 714.25
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0, 'grad_norm': 7.346324443817139, 'learning_rate': 9.999920056417383e-07, 'num_tokens': 1425630.0, 'completions/mean_length': 135.1875, 'completions/min_length': 40.0, 'completions/max_length': 224.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 135.1875, 'completions/min_terminated_length': 40.0, 'completions/max_terminated_length': 224.0, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.375, 'rewards/reflect_reward/std': 0.6094194948673248, 'rewards/reasoning_length_reward/mean': 0.8586805462837219, 'rewards/reasoning_length_reward/std': 0.25998083502054214, 'reward': 1.3592361211776733, 'reward_std': 0.3054996356368065, 'kl': 0.0039825439453125, 'kl_visual': 0.00093841552734375, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:27:00 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:27:00 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:27:00 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:27:00 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:27:00 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:27:00 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:27:00 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:27:00 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to cast start_time: 01:20.000, set to 0.
Failed to cast end_time: 01:50.000, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0, 'grad_norm': 7.870763301849365, 'learning_rate': 9.999901304280684e-07, 'num_tokens': 1590335.0, 'completions/mean_length': 124.75, 'completions/min_length': 28.0, 'completions/max_length': 236.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 124.75, 'completions/min_terminated_length': 28.0, 'completions/max_terminated_length': 236.0, 'rewards/multiturn_format_reward/mean': 0.8125, 'rewards/multiturn_format_reward/std': 0.408231720328331, 'rewards/reflect_reward/mean': 0.375, 'rewards/reflect_reward/std': 0.7104638814926147, 'rewards/reasoning_length_reward/mean': 0.8298611044883728, 'rewards/reasoning_length_reward/std': 0.21815809607505798, 'reward': 1.1659721732139587, 'reward_std': 0.4246119558811188, 'kl': 0.00494384765625, 'kl_visual': 0.00136566162109375, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:28:17 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:28:17 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:28:17 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:28:17 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:28:17 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:28:17 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:28:17 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:28:17 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to cast start_time: 00:20, set to 0.
Failed to cast end_time: 00:50, set to 0xffff.
Failed to cast start_time: 00:20, set to 0.
Failed to cast end_time: 00:50, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0001, 'grad_norm': 10.087140083312988, 'learning_rate': 9.999880578262134e-07, 'num_tokens': 1755887.0, 'completions/mean_length': 112.75, 'completions/min_length': 32.0, 'completions/max_length': 275.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 112.75, 'completions/min_terminated_length': 32.0, 'completions/max_terminated_length': 275.5, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.5625, 'rewards/reflect_reward/std': 0.6895177364349365, 'rewards/reasoning_length_reward/mean': 0.8527777791023254, 'rewards/reasoning_length_reward/std': 0.174943745136261, 'reward': 1.451805591583252, 'reward_std': 0.33427976816892624, 'kl': 0.009552001953125, 'kl_visual': 0.001644134521484375, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:29:28 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:29:28 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:29:28 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:29:28 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:29:28 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:29:28 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:29:28 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:29:28 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0001, 'grad_norm': 11.710567474365234, 'learning_rate': 9.999857878369915e-07, 'num_tokens': 1919708.0, 'completions/mean_length': 147.8125, 'completions/min_length': 38.0, 'completions/max_length': 326.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 147.8125, 'completions/min_terminated_length': 38.0, 'completions/max_terminated_length': 326.5, 'rewards/multiturn_format_reward/mean': 0.875, 'rewards/multiturn_format_reward/std': 0.3535533845424652, 'rewards/reflect_reward/mean': 0.3125, 'rewards/reflect_reward/std': 0.7255653142929077, 'rewards/reasoning_length_reward/mean': 0.9309027791023254, 'rewards/reasoning_length_reward/std': 0.13632246106863022, 'reward': 1.217430591583252, 'reward_std': 0.6020534932613373, 'kl': 0.0111541748046875, 'kl_visual': 0.001682281494140625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:30:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:30:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:30:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:30:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:30:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:30:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:30:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:30:41 [block_pool.py:264] Successfully reset prefix cache
Failed to cast start_time: 10:40, set to 0.
Failed to cast end_time: 11:50, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0001, 'grad_norm': 11.662726402282715, 'learning_rate': 9.999833204612986e-07, 'num_tokens': 2085090.0, 'completions/mean_length': 107.75, 'completions/min_length': 51.5, 'completions/max_length': 176.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 107.75, 'completions/min_terminated_length': 51.5, 'completions/max_terminated_length': 176.5, 'rewards/multiturn_format_reward/mean': 0.8125, 'rewards/multiturn_format_reward/std': 0.25877460837364197, 'rewards/reflect_reward/mean': 0.625, 'rewards/reflect_reward/std': 0.49871626496315, 'rewards/reasoning_length_reward/mean': 0.9104166626930237, 'rewards/reasoning_length_reward/std': 0.19928941130638123, 'reward': 1.3070833683013916, 'reward_std': 0.45690207183361053, 'kl': 0.0108184814453125, 'kl_visual': 0.002109527587890625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:31:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:31:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:31:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:31:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:31:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:31:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:31:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:31:41 [block_pool.py:264] Successfully reset prefix cache
Failed to cast start_time: solves for context clues used, set to 0.
Failed to cast end_time: solves for frame evidence comparison., set to 0xffff.
Failed to cast num_frames: enough for final input collected, set to 8.
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0001, 'grad_norm': 10.122605323791504, 'learning_rate': 9.999806557001091e-07, 'num_tokens': 2249538.0, 'completions/mean_length': 121.75, 'completions/min_length': 32.5, 'completions/max_length': 254.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 121.75, 'completions/min_terminated_length': 32.5, 'completions/max_terminated_length': 254.0, 'rewards/multiturn_format_reward/mean': 0.9375, 'rewards/multiturn_format_reward/std': 0.1767766922712326, 'rewards/reflect_reward/mean': 0.625, 'rewards/reflect_reward/std': 0.6094194948673248, 'rewards/reasoning_length_reward/mean': 0.803819477558136, 'rewards/reasoning_length_reward/std': 0.24265488237142563, 'reward': 1.410763919353485, 'reward_std': 0.40088433027267456, 'kl': 0.01019287109375, 'kl_visual': 0.00226593017578125, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:32:50 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:32:50 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:32:50 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:32:50 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:32:50 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:32:50 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:32:50 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:32:50 [block_pool.py:264] Successfully reset prefix cache
Failed to call tool function: fn_name='unknown', fn_args={}, got err Unknown function name: unknown, duration: 296.76
Failed to cast start_time: 00:00, set to 0.
Failed to cast end_time: 00:30, set to 0xffff.
Failed to cast start_time: 03:20, set to 0.
Failed to cast end_time: 03:45, set to 0xffff.
Failed to cast start_time: 00:00, set to 0.
Failed to cast end_time: 02:50, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0001, 'grad_norm': 9.791261672973633, 'learning_rate': 9.99977793554475e-07, 'num_tokens': 2384682.0, 'completions/mean_length': 121.0625, 'completions/min_length': 43.5, 'completions/max_length': 193.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 121.0625, 'completions/min_terminated_length': 43.5, 'completions/max_terminated_length': 193.5, 'rewards/multiturn_format_reward/mean': 0.875, 'rewards/multiturn_format_reward/std': 0.3535533845424652, 'rewards/reflect_reward/mean': 0.75, 'rewards/reflect_reward/std': 0.7071067690849304, 'rewards/reasoning_length_reward/mean': 0.8812499940395355, 'rewards/reasoning_length_reward/std': 0.21113040298223495, 'reward': 1.4262500405311584, 'reward_std': 0.5901532173156738, 'kl': 0.0115966796875, 'kl_visual': 0.00157928466796875, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:33:59 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:33:59 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:33:59 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:33:59 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:33:59 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:33:59 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:33:59 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:33:59 [block_pool.py:264] Successfully reset prefix cache
Failed to cast start_time: 04:00, set to 0.
Failed to cast end_time: 04:30, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to cast start_time: 74.4s, set to 0.
Failed to cast end_time: 1067.0s, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0001, 'grad_norm': 6.991304397583008, 'learning_rate': 9.999747340255258e-07, 'num_tokens': 2549273.0, 'completions/mean_length': 133.1875, 'completions/min_length': 42.5, 'completions/max_length': 281.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 133.1875, 'completions/min_terminated_length': 42.5, 'completions/max_terminated_length': 281.5, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.4375, 'rewards/reflect_reward/std': 0.6123279929161072, 'rewards/reasoning_length_reward/mean': 0.8138888776302338, 'rewards/reasoning_length_reward/std': 0.2091551423072815, 'reward': 1.3815277814865112, 'reward_std': 0.2989083081483841, 'kl': 0.008331298828125, 'kl_visual': 0.00266265869140625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:35:12 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:35:12 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:35:12 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:35:12 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:35:12 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:35:12 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:35:12 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:35:12 [block_pool.py:264] Successfully reset prefix cache
Failed to cast start_time: 06:00, set to 0.
Failed to cast end_time: 06:30, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0001, 'grad_norm': 9.694098472595215, 'learning_rate': 9.999714771144699e-07, 'num_tokens': 2713549.0, 'completions/mean_length': 112.0625, 'completions/min_length': 49.5, 'completions/max_length': 161.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 112.0625, 'completions/min_terminated_length': 49.5, 'completions/max_terminated_length': 161.0, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.5, 'rewards/reflect_reward/std': 0.6307865381240845, 'rewards/reasoning_length_reward/mean': 0.8559027910232544, 'rewards/reasoning_length_reward/std': 0.2298787534236908, 'reward': 1.4211806058883667, 'reward_std': 0.31924140453338623, 'kl': 0.01531982421875, 'kl_visual': 0.0038909912109375, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:36:05 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:36:05 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:36:05 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:36:05 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:36:05 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:36:05 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:36:05 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:36:05 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to cast start_time: 0.0s, set to 0.
Failed to cast end_time: 0.5s, set to 0xffff.
Failed to cast start_time: 198.3s, set to 0.
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0001, 'grad_norm': 20.124792098999023, 'learning_rate': 9.999680228225929e-07, 'num_tokens': 2857543.0, 'completions/mean_length': 113.0625, 'completions/min_length': 63.5, 'completions/max_length': 173.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 113.0625, 'completions/min_terminated_length': 63.5, 'completions/max_terminated_length': 173.5, 'rewards/multiturn_format_reward/mean': 0.9375, 'rewards/multiturn_format_reward/std': 0.1767766922712326, 'rewards/reflect_reward/mean': 0.5, 'rewards/reflect_reward/std': 0.9258201122283936, 'rewards/reasoning_length_reward/mean': 0.7809028029441833, 'rewards/reasoning_length_reward/std': 0.20989639312028885, 'reward': 1.3436806201934814, 'reward_std': 0.63133704662323, 'kl': 0.01519775390625, 'kl_visual': 0.00283050537109375, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:37:01 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:37:01 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:37:01 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:37:01 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:37:01 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:37:01 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:37:01 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:37:01 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0001, 'grad_norm': 11.565966606140137, 'learning_rate': 9.999643711512585e-07, 'num_tokens': 3000704.0, 'completions/mean_length': 127.0625, 'completions/min_length': 38.5, 'completions/max_length': 266.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 127.0625, 'completions/min_terminated_length': 38.5, 'completions/max_terminated_length': 266.0, 'rewards/multiturn_format_reward/mean': 0.8125, 'rewards/multiturn_format_reward/std': 0.408231720328331, 'rewards/reflect_reward/mean': 0.5625, 'rewards/reflect_reward/std': 0.5303300768136978, 'rewards/reasoning_length_reward/mean': 0.8888888955116272, 'rewards/reasoning_length_reward/std': 0.17726028710603714, 'reward': 1.2715277671813965, 'reward_std': 0.509910985827446, 'kl': 0.018585205078125, 'kl_visual': 0.0036773681640625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:38:01 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:38:01 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:38:01 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:38:01 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:38:01 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:38:01 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:38:01 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:38:01 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to cast start_time: 03:00, set to 0.
Failed to cast end_time: 05:00, set to 0xffff.
Failed to cast start_time: 03:00, set to 0.
Failed to cast end_time: 05:00, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0001, 'grad_norm': 7.742677688598633, 'learning_rate': 9.999605221019081e-07, 'num_tokens': 3140861.0, 'completions/mean_length': 117.0625, 'completions/min_length': 59.5, 'completions/max_length': 163.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 117.0625, 'completions/min_terminated_length': 59.5, 'completions/max_terminated_length': 163.0, 'rewards/multiturn_format_reward/mean': 0.9375, 'rewards/multiturn_format_reward/std': 0.1767766922712326, 'rewards/reflect_reward/mean': 0.875, 'rewards/reflect_reward/std': 0.3535533845424652, 'rewards/reasoning_length_reward/mean': 0.9072916507720947, 'rewards/reasoning_length_reward/std': 0.14800028130412102, 'reward': 1.5564583539962769, 'reward_std': 0.35754892230033875, 'kl': 0.013916015625, 'kl_visual': 0.00260162353515625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:39:04 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:39:04 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:39:04 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:39:04 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:39:04 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:39:04 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:39:04 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:39:04 [block_pool.py:264] Successfully reset prefix cache
Failed to call tool function: fn_name='unknown', fn_args={}, got err Unknown function name: unknown, duration: 59.12
Failed to call tool function: fn_name='unknown', fn_args={}, got err Unknown function name: unknown, duration: 59.12
Failed to call tool function: fn_name='unknown', fn_args={}, got err Unknown function name: unknown, duration: 59.12
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0001, 'grad_norm': 28.16373062133789, 'learning_rate': 9.999564756760614e-07, 'num_tokens': 3258523.0, 'completions/mean_length': 114.0625, 'completions/min_length': 45.0, 'completions/max_length': 176.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 114.0625, 'completions/min_terminated_length': 45.0, 'completions/max_terminated_length': 176.0, 'rewards/multiturn_format_reward/mean': 0.9375, 'rewards/multiturn_format_reward/std': 0.1767766922712326, 'rewards/reflect_reward/mean': 0.75, 'rewards/reflect_reward/std': 0.5850084125995636, 'rewards/reasoning_length_reward/mean': 0.8076388835906982, 'rewards/reasoning_length_reward/std': 0.23277908563613892, 'reward': 1.4740277528762817, 'reward_std': 0.4778882712125778, 'kl': 0.015533447265625, 'kl_visual': 0.003814697265625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:40:10 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:40:10 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:40:10 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:40:10 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:40:10 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:40:10 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:40:10 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:40:10 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0001, 'grad_norm': 25.51059913635254, 'learning_rate': 9.99952231875316e-07, 'num_tokens': 3424811.0, 'completions/mean_length': 99.5625, 'completions/min_length': 51.0, 'completions/max_length': 147.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 99.5625, 'completions/min_terminated_length': 51.0, 'completions/max_terminated_length': 147.5, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.375, 'rewards/reflect_reward/std': 0.6208146214485168, 'rewards/reasoning_length_reward/mean': 0.7635416388511658, 'rewards/reasoning_length_reward/std': 0.22130275517702103, 'reward': 1.340208351612091, 'reward_std': 0.3200858235359192, 'kl': 0.02008056640625, 'kl_visual': 0.00270843505859375, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:41:15 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:41:15 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:41:15 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:41:15 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:41:15 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:41:15 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:41:15 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:41:15 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0002, 'grad_norm': 9.855920791625977, 'learning_rate': 9.999477907013472e-07, 'num_tokens': 3588128.0, 'completions/mean_length': 106.125, 'completions/min_length': 30.0, 'completions/max_length': 228.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 106.125, 'completions/min_terminated_length': 30.0, 'completions/max_terminated_length': 228.0, 'rewards/multiturn_format_reward/mean': 0.9375, 'rewards/multiturn_format_reward/std': 0.1767766922712326, 'rewards/reflect_reward/mean': 0.5, 'rewards/reflect_reward/std': 0.6307865381240845, 'rewards/reasoning_length_reward/mean': 0.7958333492279053, 'rewards/reasoning_length_reward/std': 0.23602232336997986, 'reward': 1.346666693687439, 'reward_std': 0.45708802342414856, 'kl': 0.0377197265625, 'kl_visual': 0.0034027099609375, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:42:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:42:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:42:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:42:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:42:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:42:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:42:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:42:41 [block_pool.py:264] Successfully reset prefix cache
Failed to cast start_time: 04:20-04:50, set to 0.
Failed to cast end_time: 04:50, set to 0xffff.
Failed to cast start_time: Between 00:20-00:50, set to 0.
Failed to cast end_time: Between 00:00-00:30, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to cast start_time: 00:00.00, set to 0.
Failed to cast end_time: 03:00.00, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0002, 'grad_norm': 9.821464538574219, 'learning_rate': 9.99943152155908e-07, 'num_tokens': 3751255.0, 'completions/mean_length': 97.3125, 'completions/min_length': 31.5, 'completions/max_length': 157.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 97.3125, 'completions/min_terminated_length': 31.5, 'completions/max_terminated_length': 157.0, 'rewards/multiturn_format_reward/mean': 0.9375, 'rewards/multiturn_format_reward/std': 0.1767766922712326, 'rewards/reflect_reward/mean': 0.5625, 'rewards/reflect_reward/std': 0.5303300768136978, 'rewards/reasoning_length_reward/mean': 0.866666704416275, 'rewards/reasoning_length_reward/std': 0.21418194472789764, 'reward': 1.3920834064483643, 'reward_std': 0.4577972739934921, 'kl': 0.03564453125, 'kl_visual': 0.00289154052734375, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:43:44 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:43:44 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:43:44 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:43:44 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:43:44 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:43:44 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:43:44 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:43:44 [block_pool.py:264] Successfully reset prefix cache
Failed to cast start_time: 00:00-00:30, set to 0.
Failed to cast end_time: 06:00-06:30, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0003, 'grad_norm': 14.116141319274902, 'learning_rate': 9.999383162408303e-07, 'num_tokens': 3916292.0, 'completions/mean_length': 114.0625, 'completions/min_length': 23.0, 'completions/max_length': 169.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 114.0625, 'completions/min_terminated_length': 23.0, 'completions/max_terminated_length': 169.0, 'rewards/multiturn_format_reward/mean': 0.9375, 'rewards/multiturn_format_reward/std': 0.1767766922712326, 'rewards/reflect_reward/mean': 0.3125, 'rewards/reflect_reward/std': 0.7952259480953217, 'rewards/reasoning_length_reward/mean': 0.819444477558136, 'rewards/reasoning_length_reward/std': 0.25613754987716675, 'reward': 1.257638931274414, 'reward_std': 0.4964020103216171, 'kl': 0.0526123046875, 'kl_visual': 0.0039825439453125, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:44:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:44:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:44:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:44:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:44:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:44:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:44:41 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:44:41 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to call tool function: fn_name='seek_video_frames', fn_args={'query': "A character's inventory in the 10th clip (03:00-03:30) has Press vest", 'start_time': 300.0, 'end_time': 330.0, 'num_frames': 8}, got err The number of frames to select could not be 0. query: A character's inventory in the 10th clip (03:00-03:30) has Press vest, start_time: 300.0, end_time: 330.0, num_frames: 8, duration: 234.67
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0003, 'grad_norm': 5.7224907875061035, 'learning_rate': 9.999332829580226e-07, 'num_tokens': 4047875.0, 'completions/mean_length': 107.875, 'completions/min_length': 57.0, 'completions/max_length': 177.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 107.875, 'completions/min_terminated_length': 57.0, 'completions/max_terminated_length': 177.5, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.8125, 'rewards/reflect_reward/std': 0.25877460837364197, 'rewards/reasoning_length_reward/mean': 0.8697916865348816, 'rewards/reasoning_length_reward/std': 0.21517415344715118, 'reward': 1.5802083611488342, 'reward_std': 0.15468415059149265, 'kl': 0.0499267578125, 'kl_visual': 0.0045166015625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:45:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:45:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:45:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:45:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:45:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:45:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:45:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:45:35 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to cast start_time: 01:20-01:30, set to 0.
Failed to cast end_time: 01:50, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0002, 'grad_norm': 5.899713039398193, 'learning_rate': 9.999280523094722e-07, 'num_tokens': 4214202.0, 'completions/mean_length': 132.4375, 'completions/min_length': 67.5, 'completions/max_length': 199.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 132.4375, 'completions/min_terminated_length': 67.5, 'completions/max_terminated_length': 199.0, 'rewards/multiturn_format_reward/mean': 0.9375, 'rewards/multiturn_format_reward/std': 0.1767766922712326, 'rewards/reflect_reward/mean': 0.4375, 'rewards/reflect_reward/std': 0.6123279929161072, 'rewards/reasoning_length_reward/mean': 0.8177083432674408, 'rewards/reasoning_length_reward/std': 0.27095093578100204, 'reward': 1.3197917342185974, 'reward_std': 0.307579830288887, 'kl': 0.03515625, 'kl_visual': 0.00830078125, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:46:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:46:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:46:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:46:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:46:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:46:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:46:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:46:35 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to call tool function: fn_name='unknown', fn_args={}, got err Unknown function name: unknown, duration: 640.07
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0003, 'grad_norm': 9.000255584716797, 'learning_rate': 9.999226242972443e-07, 'num_tokens': 4352774.0, 'completions/mean_length': 101.5, 'completions/min_length': 43.5, 'completions/max_length': 165.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 101.5, 'completions/min_terminated_length': 43.5, 'completions/max_terminated_length': 165.5, 'rewards/multiturn_format_reward/mean': 0.9375, 'rewards/multiturn_format_reward/std': 0.1767766922712326, 'rewards/reflect_reward/mean': 0.5, 'rewards/reflect_reward/std': 0.744023859500885, 'rewards/reasoning_length_reward/mean': 0.835069477558136, 'rewards/reasoning_length_reward/std': 0.1630975902080536, 'reward': 1.3545138835906982, 'reward_std': 0.4086655080318451, 'kl': 0.053955078125, 'kl_visual': 0.0066986083984375, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:47:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:47:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:47:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:47:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:47:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:47:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:47:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:47:39 [block_pool.py:264] Successfully reset prefix cache
Failed to cast start_time: beginning of the video, set to 0.
Failed to cast end_time: end of the video, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to cast start_time: 03:20.000, set to 0.
Failed to cast end_time: 03:50.000, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0002, 'grad_norm': 14.494394302368164, 'learning_rate': 9.999169989234813e-07, 'num_tokens': 4509486.0, 'completions/mean_length': 120.3125, 'completions/min_length': 62.5, 'completions/max_length': 164.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 120.3125, 'completions/min_terminated_length': 62.5, 'completions/max_terminated_length': 164.5, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.375, 'rewards/reflect_reward/std': 0.7892734110355377, 'rewards/reasoning_length_reward/mean': 0.843402773141861, 'rewards/reasoning_length_reward/std': 0.1613481566309929, 'reward': 1.3561805486679077, 'reward_std': 0.3900223970413208, 'kl': 0.0374755859375, 'kl_visual': 0.00848388671875, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:49:44 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:49:44 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:49:44 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:49:44 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:49:44 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:49:44 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:49:44 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:49:44 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to cast start_time: 9:20, set to 0.
Failed to cast end_time: 9:50, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0003, 'grad_norm': 10.769880294799805, 'learning_rate': 9.999111761904044e-07, 'num_tokens': 4670788.0, 'completions/mean_length': 116.8125, 'completions/min_length': 64.5, 'completions/max_length': 136.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 116.8125, 'completions/min_terminated_length': 64.5, 'completions/max_terminated_length': 136.5, 'rewards/multiturn_format_reward/mean': 0.9375, 'rewards/multiturn_format_reward/std': 0.1767766922712326, 'rewards/reflect_reward/mean': 0.375, 'rewards/reflect_reward/std': 0.6924469172954559, 'rewards/reasoning_length_reward/mean': 0.8510416746139526, 'rewards/reasoning_length_reward/std': 0.12690375000238419, 'reward': 1.2952083945274353, 'reward_std': 0.40267105400562286, 'kl': 0.0472412109375, 'kl_visual': 0.00982666015625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:50:40 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:50:40 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:50:40 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:50:40 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:50:40 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:50:40 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:50:40 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:50:40 [block_pool.py:264] Successfully reset prefix cache
Failed to cast start_time: 02:00, set to 0.
Failed to cast end_time: 02:50, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to cast start_time: 1.5s, set to 0.
Failed to cast end_time: 16.5s, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0002, 'grad_norm': 6.217945575714111, 'learning_rate': 9.999051561003122e-07, 'num_tokens': 4806609.0, 'completions/mean_length': 129.0625, 'completions/min_length': 73.5, 'completions/max_length': 175.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 129.0625, 'completions/min_terminated_length': 73.5, 'completions/max_terminated_length': 175.5, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.8125, 'rewards/reflect_reward/std': 0.25877460837364197, 'rewards/reasoning_length_reward/mean': 0.8427083194255829, 'rewards/reasoning_length_reward/std': 0.1745520643889904, 'reward': 1.5747917294502258, 'reward_std': 0.14709427580237389, 'kl': 0.03350830078125, 'kl_visual': 0.011138916015625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:51:42 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:51:42 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:51:42 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:51:42 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:51:42 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:51:42 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:51:42 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:51:42 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0004, 'grad_norm': 10.292461395263672, 'learning_rate': 9.998989386555814e-07, 'num_tokens': 4973671.0, 'completions/mean_length': 116.5625, 'completions/min_length': 41.0, 'completions/max_length': 154.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 116.5625, 'completions/min_terminated_length': 41.0, 'completions/max_terminated_length': 154.5, 'rewards/multiturn_format_reward/mean': 0.9375, 'rewards/multiturn_format_reward/std': 0.1767766922712326, 'rewards/reflect_reward/mean': 0.625, 'rewards/reflect_reward/std': 0.49871626496315, 'rewards/reasoning_length_reward/mean': 0.8125, 'rewards/reasoning_length_reward/std': 0.21115288883447647, 'reward': 1.412500023841858, 'reward_std': 0.40028373897075653, 'kl': 0.0650634765625, 'kl_visual': 0.008544921875, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:52:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:52:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:52:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:52:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:52:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:52:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:52:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:52:39 [block_pool.py:264] Successfully reset prefix cache
Failed to call tool function: fn_name='unknown', fn_args={}, got err Unknown function name: unknown, duration: 1129.26
Failed to call tool function: fn_name='unknown', fn_args={}, got err Unknown function name: unknown, duration: 1129.26
Failed to cast start_time: 0.0s, set to 0.
Failed to cast end_time: 0.0s, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0003, 'grad_norm': 11.013411521911621, 'learning_rate': 9.998925238586663e-07, 'num_tokens': 5140077.0, 'completions/mean_length': 122.25, 'completions/min_length': 43.5, 'completions/max_length': 244.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 122.25, 'completions/min_terminated_length': 43.5, 'completions/max_terminated_length': 244.5, 'rewards/multiturn_format_reward/mean': 0.875, 'rewards/multiturn_format_reward/std': 0.3535533845424652, 'rewards/reflect_reward/mean': 0.375, 'rewards/reflect_reward/std': 0.8211671113967896, 'rewards/reasoning_length_reward/mean': 0.800347238779068, 'rewards/reasoning_length_reward/std': 0.22220851480960846, 'reward': 1.222569465637207, 'reward_std': 0.5110327750444412, 'kl': 0.0560302734375, 'kl_visual': 0.007720947265625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:53:46 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:53:46 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:53:46 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:53:46 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:53:46 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:53:46 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:53:46 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:53:46 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0011, 'grad_norm': 5.1830668449401855, 'learning_rate': 9.998859117121e-07, 'num_tokens': 5258653.0, 'completions/mean_length': 116.5, 'completions/min_length': 41.0, 'completions/max_length': 192.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 116.5, 'completions/min_terminated_length': 41.0, 'completions/max_terminated_length': 192.5, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.75, 'rewards/reflect_reward/std': 0.5487886220216751, 'rewards/reasoning_length_reward/mean': 0.8798611164093018, 'rewards/reasoning_length_reward/std': 0.09533601254224777, 'reward': 1.5509722828865051, 'reward_std': 0.2852170392870903, 'kl': 0.2188720703125, 'kl_visual': 0.0089111328125, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:55:00 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:55:00 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:55:00 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:55:00 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:55:00 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:55:00 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:55:00 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:55:00 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to call tool function: fn_name='unknown', fn_args={}, got err Unknown function name: unknown, duration: 2486.77
Failed to cast start_time: 170.0s, set to 0.
Failed to call tool function: fn_name='unknown', fn_args={}, got err Unknown function name: unknown, duration: 2486.77
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0005, 'grad_norm': 5.0359601974487305, 'learning_rate': 9.99879102218492e-07, 'num_tokens': 5423994.0, 'completions/mean_length': 115.75, 'completions/min_length': 34.5, 'completions/max_length': 157.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 115.75, 'completions/min_terminated_length': 34.5, 'completions/max_terminated_length': 157.0, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.625, 'rewards/reflect_reward/std': 0.6094194948673248, 'rewards/reasoning_length_reward/mean': 0.9055555462837219, 'rewards/reasoning_length_reward/std': 0.1660255640745163, 'reward': 1.4936111569404602, 'reward_std': 0.3026103749871254, 'kl': 0.096435546875, 'kl_visual': 0.012786865234375, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:56:30 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:56:30 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:56:30 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:56:30 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:56:30 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:56:30 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:56:30 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:56:30 [block_pool.py:264] Successfully reset prefix cache
Failed to cast start_time: 06:00, set to 0.
Failed to cast end_time: 13:30, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to cast start_time: 2.5s, set to 0.
Failed to cast end_time: 1016.65s, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.001, 'grad_norm': 12.652992248535156, 'learning_rate': 9.99872095380531e-07, 'num_tokens': 5589655.0, 'completions/mean_length': 110.8125, 'completions/min_length': 37.0, 'completions/max_length': 180.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 110.8125, 'completions/min_terminated_length': 37.0, 'completions/max_terminated_length': 180.5, 'rewards/multiturn_format_reward/mean': 0.8125, 'rewards/multiturn_format_reward/std': 0.408231720328331, 'rewards/reflect_reward/mean': 0.5625, 'rewards/reflect_reward/std': 0.7255653142929077, 'rewards/reasoning_length_reward/mean': 0.8298611044883728, 'rewards/reasoning_length_reward/std': 0.2525380104780197, 'reward': 1.2597222328186035, 'reward_std': 0.6446585059165955, 'kl': 0.186767578125, 'kl_visual': 0.010162353515625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:57:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:57:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:57:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:57:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:57:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:57:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:57:39 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:57:39 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.001, 'grad_norm': 19.136863708496094, 'learning_rate': 9.998648912009833e-07, 'num_tokens': 5755244.0, 'completions/mean_length': 102.6875, 'completions/min_length': 50.0, 'completions/max_length': 135.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 102.6875, 'completions/min_terminated_length': 50.0, 'completions/max_terminated_length': 135.0, 'rewards/multiturn_format_reward/mean': 0.9375, 'rewards/multiturn_format_reward/std': 0.1767766922712326, 'rewards/reflect_reward/mean': 0.375, 'rewards/reflect_reward/std': 0.7315178513526917, 'rewards/reasoning_length_reward/mean': 0.7864583134651184, 'rewards/reasoning_length_reward/std': 0.2512615919113159, 'reward': 1.2822916507720947, 'reward_std': 0.47119227051734924, 'kl': 0.17724609375, 'kl_visual': 0.012908935546875, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:58:38 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:58:38 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:58:38 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:58:38 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:58:38 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:58:38 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:58:38 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:58:38 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to cast start_time: 00:40, set to 0.
Failed to cast end_time: 01:10, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.001, 'grad_norm': 10.358992576599121, 'learning_rate': 9.99857489682693e-07, 'num_tokens': 5922115.0, 'completions/mean_length': 118.6875, 'completions/min_length': 29.5, 'completions/max_length': 168.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 118.6875, 'completions/min_terminated_length': 29.5, 'completions/max_terminated_length': 168.0, 'rewards/multiturn_format_reward/mean': 0.9375, 'rewards/multiturn_format_reward/std': 0.1767766922712326, 'rewards/reflect_reward/mean': 0.375, 'rewards/reflect_reward/std': 0.7892734110355377, 'rewards/reasoning_length_reward/mean': 0.875, 'rewards/reasoning_length_reward/std': 0.2646574154496193, 'reward': 1.3000000715255737, 'reward_std': 0.5354167073965073, 'kl': 0.18115234375, 'kl_visual': 0.011993408203125, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 21:59:42 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:59:42 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:59:42 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:59:42 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:59:42 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:59:42 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:59:42 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 21:59:42 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0007, 'grad_norm': 13.409210205078125, 'learning_rate': 9.998498908285819e-07, 'num_tokens': 6090016.0, 'completions/mean_length': 126.1875, 'completions/min_length': 55.5, 'completions/max_length': 196.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 126.1875, 'completions/min_terminated_length': 55.5, 'completions/max_terminated_length': 196.5, 'rewards/multiturn_format_reward/mean': 0.9375, 'rewards/multiturn_format_reward/std': 0.1767766922712326, 'rewards/reflect_reward/mean': 0.375, 'rewards/reflect_reward/std': 0.8211671113967896, 'rewards/reasoning_length_reward/mean': 0.8291666805744171, 'rewards/reasoning_length_reward/std': 0.1813446544110775, 'reward': 1.2908333539962769, 'reward_std': 0.41511036455631256, 'kl': 0.127197265625, 'kl_visual': 0.0123291015625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 22:01:38 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:01:38 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:01:38 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:01:38 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:01:38 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:01:38 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:01:38 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:01:38 [block_pool.py:264] Successfully reset prefix cache
Failed to cast start_time: None, set to 0.
Failed to cast end_time: None, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0014, 'grad_norm': 35.29399490356445, 'learning_rate': 9.998420946416499e-07, 'num_tokens': 6244247.0, 'completions/mean_length': 117.1875, 'completions/min_length': 46.5, 'completions/max_length': 183.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 117.1875, 'completions/min_terminated_length': 46.5, 'completions/max_terminated_length': 183.5, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.3125, 'rewards/reflect_reward/std': 0.880171537399292, 'rewards/reasoning_length_reward/mean': 0.9270833730697632, 'rewards/reasoning_length_reward/std': 0.11301689594984055, 'reward': 1.3416666984558105, 'reward_std': 0.44509899616241455, 'kl': 0.2666015625, 'kl_visual': 0.01123046875, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 22:02:32 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:02:32 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:02:32 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:02:32 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:02:32 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:02:32 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:02:32 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:02:32 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to cast start_time: 8.0s, set to 0.
Failed to cast end_time: 15.0s, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0009, 'grad_norm': 10.095902442932129, 'learning_rate': 9.99834101124975e-07, 'num_tokens': 6383380.0, 'completions/mean_length': 114.0625, 'completions/min_length': 52.0, 'completions/max_length': 162.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 114.0625, 'completions/min_terminated_length': 52.0, 'completions/max_terminated_length': 162.5, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.3125, 'rewards/reflect_reward/std': 0.7833450436592102, 'rewards/reasoning_length_reward/mean': 0.8614583015441895, 'rewards/reasoning_length_reward/std': 0.16606194525957108, 'reward': 1.32854163646698, 'reward_std': 0.3803146034479141, 'kl': 0.1787109375, 'kl_visual': 0.0089111328125, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 22:03:30 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:03:30 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:03:30 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:03:30 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:03:30 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:03:30 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:03:30 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:03:30 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0009, 'grad_norm': 17.767969131469727, 'learning_rate': 9.99825910281713e-07, 'num_tokens': 6545520.0, 'completions/mean_length': 124.75, 'completions/min_length': 49.5, 'completions/max_length': 171.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 124.75, 'completions/min_terminated_length': 49.5, 'completions/max_terminated_length': 171.0, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.4375, 'rewards/reflect_reward/std': 0.6123279929161072, 'rewards/reasoning_length_reward/mean': 0.9097222089767456, 'rewards/reasoning_length_reward/std': 0.15303443744778633, 'reward': 1.4006944298744202, 'reward_std': 0.305788591504097, 'kl': 0.174072265625, 'kl_visual': 0.010467529296875, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 22:04:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:04:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:04:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:04:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:04:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:04:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:04:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:04:35 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0016, 'grad_norm': 10.579375267028809, 'learning_rate': 9.99817522115097e-07, 'num_tokens': 6710838.0, 'completions/mean_length': 112.75, 'completions/min_length': 30.0, 'completions/max_length': 188.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 112.75, 'completions/min_terminated_length': 30.0, 'completions/max_terminated_length': 188.5, 'rewards/multiturn_format_reward/mean': 0.875, 'rewards/multiturn_format_reward/std': 0.2314550280570984, 'rewards/reflect_reward/mean': 0.4375, 'rewards/reflect_reward/std': 0.6367390751838684, 'rewards/reasoning_length_reward/mean': 0.8211805820465088, 'rewards/reasoning_length_reward/std': 0.24047620594501495, 'reward': 1.2579861283302307, 'reward_std': 0.3757800906896591, 'kl': 0.29052734375, 'kl_visual': 0.023834228515625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 22:05:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:05:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:05:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:05:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:05:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:05:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:05:35 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:05:35 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0018, 'grad_norm': 19.870288848876953, 'learning_rate': 9.998089366284391e-07, 'num_tokens': 6837204.0, 'completions/mean_length': 128.9375, 'completions/min_length': 63.5, 'completions/max_length': 164.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 128.9375, 'completions/min_terminated_length': 63.5, 'completions/max_terminated_length': 164.5, 'rewards/multiturn_format_reward/mean': 0.9375, 'rewards/multiturn_format_reward/std': 0.1767766922712326, 'rewards/reflect_reward/mean': 0.75, 'rewards/reflect_reward/std': 0.5850084125995636, 'rewards/reasoning_length_reward/mean': 0.8819444477558136, 'rewards/reasoning_length_reward/std': 0.2516259476542473, 'reward': 1.4888888597488403, 'reward_std': 0.48939602077007294, 'kl': 0.35302734375, 'kl_visual': 0.012542724609375, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 22:07:20 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:07:20 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:07:20 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:07:20 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:07:20 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:07:20 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:07:20 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:07:20 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0017, 'grad_norm': 2.9363343715667725, 'learning_rate': 9.998001538251282e-07, 'num_tokens': 7002441.0, 'completions/mean_length': 119.375, 'completions/min_length': 46.5, 'completions/max_length': 162.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 119.375, 'completions/min_terminated_length': 46.5, 'completions/max_terminated_length': 162.0, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.9375, 'rewards/reflect_reward/std': 0.1767766922712326, 'rewards/reasoning_length_reward/mean': 0.8211805522441864, 'rewards/reasoning_length_reward/std': 0.26636237651109695, 'reward': 1.6329861283302307, 'reward_std': 0.11032221652567387, 'kl': 0.329833984375, 'kl_visual': 0.013519287109375, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 22:08:31 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:08:31 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:08:31 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:08:31 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:08:31 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:08:31 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:08:31 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:08:31 [block_pool.py:264] Successfully reset prefix cache
Failed to call tool function: fn_name='unknown', fn_args={}, got err Unknown function name: unknown, duration: 893.86
Failed to call tool function: fn_name='unknown', fn_args={}, got err Unknown function name: unknown, duration: 893.86
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0008, 'grad_norm': 9.316038131713867, 'learning_rate': 9.99791173708632e-07, 'num_tokens': 7168327.0, 'completions/mean_length': 125.9375, 'completions/min_length': 87.5, 'completions/max_length': 160.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 125.9375, 'completions/min_terminated_length': 87.5, 'completions/max_terminated_length': 160.0, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.6875, 'rewards/reflect_reward/std': 0.6034669578075409, 'rewards/reasoning_length_reward/mean': 0.8260416686534882, 'rewards/reasoning_length_reward/std': 0.1934751272201538, 'reward': 1.508958339691162, 'reward_std': 0.2993929013609886, 'kl': 0.1396484375, 'kl_visual': 0.01495361328125, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 22:09:54 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:09:54 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:09:54 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:09:54 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:09:54 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:09:54 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:09:54 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:09:54 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to cast start_time: 00:00, set to 0.
Failed to cast end_time: 06:59, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0006, 'grad_norm': 5.445191860198975, 'learning_rate': 9.997819962824955e-07, 'num_tokens': 7306430.0, 'completions/mean_length': 138.0, 'completions/min_length': 73.0, 'completions/max_length': 172.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 138.0, 'completions/min_terminated_length': 73.0, 'completions/max_terminated_length': 172.5, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.75, 'rewards/reflect_reward/std': 0.5850084125995636, 'rewards/reasoning_length_reward/mean': 0.8020833432674408, 'rewards/reasoning_length_reward/std': 0.2642545849084854, 'reward': 1.5354167222976685, 'reward_std': 0.28779080510139465, 'kl': 0.103271484375, 'kl_visual': 0.013885498046875, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 22:10:47 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:10:47 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:10:47 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:10:47 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:10:47 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:10:47 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:10:47 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:10:47 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0105, 'grad_norm': 24.47235107421875, 'learning_rate': 9.997726215503421e-07, 'num_tokens': 7441563.0, 'completions/mean_length': 126.875, 'completions/min_length': 53.0, 'completions/max_length': 161.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 126.875, 'completions/min_terminated_length': 53.0, 'completions/max_terminated_length': 161.5, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.8125, 'rewards/reflect_reward/std': 0.25877460837364197, 'rewards/reasoning_length_reward/mean': 0.9437500238418579, 'rewards/reasoning_length_reward/std': 0.11107441410422325, 'reward': 1.5950000286102295, 'reward_std': 0.1339592430740595, 'kl': 2.0888671875, 'kl_visual': 0.0172119140625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 22:11:53 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:11:53 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:11:53 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:11:53 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:11:53 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:11:53 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:11:53 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:11:53 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to cast start_time: 01:00.000, set to 0.
Failed to cast end_time: 01:30.000, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0062, 'grad_norm': 26.685916900634766, 'learning_rate': 9.997630495158725e-07, 'num_tokens': 7607010.0, 'completions/mean_length': 121.875, 'completions/min_length': 30.0, 'completions/max_length': 174.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 121.875, 'completions/min_terminated_length': 30.0, 'completions/max_terminated_length': 174.0, 'rewards/multiturn_format_reward/mean': 0.9375, 'rewards/multiturn_format_reward/std': 0.1767766922712326, 'rewards/reflect_reward/mean': 0.375, 'rewards/reflect_reward/std': 0.6760360896587372, 'rewards/reasoning_length_reward/mean': 0.8506944179534912, 'rewards/reasoning_length_reward/std': 0.1923292577266693, 'reward': 1.295138955116272, 'reward_std': 0.3553190529346466, 'kl': 1.234375, 'kl_visual': 0.01385498046875, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 22:12:55 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:12:55 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:12:55 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:12:55 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:12:55 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:12:55 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:12:55 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:12:55 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0018, 'grad_norm': 7.1001176834106445, 'learning_rate': 9.997532801828658e-07, 'num_tokens': 7755245.0, 'completions/mean_length': 134.8125, 'completions/min_length': 40.0, 'completions/max_length': 181.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 134.8125, 'completions/min_terminated_length': 40.0, 'completions/max_terminated_length': 181.0, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.5, 'rewards/reflect_reward/std': 0.8408745229244232, 'rewards/reasoning_length_reward/mean': 0.8715277910232544, 'rewards/reasoning_length_reward/std': 0.19748081266880035, 'reward': 1.4243055582046509, 'reward_std': 0.4280136972665787, 'kl': 0.3447265625, 'kl_visual': 0.0172119140625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 22:13:56 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:13:56 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:13:56 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:13:56 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:13:56 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:13:56 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:13:56 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:13:56 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0155, 'grad_norm': 18.25221061706543, 'learning_rate': 9.997433135551785e-07, 'num_tokens': 7921979.0, 'completions/mean_length': 131.0, 'completions/min_length': 46.5, 'completions/max_length': 203.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 131.0, 'completions/min_terminated_length': 46.5, 'completions/max_terminated_length': 203.5, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.5625, 'rewards/reflect_reward/std': 0.5260358452796936, 'rewards/reasoning_length_reward/mean': 0.8961805701255798, 'rewards/reasoning_length_reward/std': 0.15642430633306503, 'reward': 1.460486114025116, 'reward_std': 0.2789670079946518, 'kl': 3.0703125, 'kl_visual': 0.01287841796875, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 22:15:46 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:15:46 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:15:46 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:15:46 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:15:46 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:15:46 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:15:46 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:15:46 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0019, 'grad_norm': 9.757218360900879, 'learning_rate': 9.997331496367454e-07, 'num_tokens': 8086877.0, 'completions/mean_length': 119.125, 'completions/min_length': 53.5, 'completions/max_length': 169.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 119.125, 'completions/min_terminated_length': 53.5, 'completions/max_terminated_length': 169.0, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.5, 'rewards/reflect_reward/std': 0.5940381735563278, 'rewards/reasoning_length_reward/mean': 0.8923611342906952, 'rewards/reasoning_length_reward/std': 0.1253227386623621, 'reward': 1.4284722805023193, 'reward_std': 0.30794544517993927, 'kl': 0.36767578125, 'kl_visual': 0.016845703125, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 22:16:53 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:16:53 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:16:53 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:16:53 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:16:53 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:16:53 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:16:53 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:16:53 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0039, 'grad_norm': 9.3490571975708, 'learning_rate': 9.997227884315792e-07, 'num_tokens': 8252662.0, 'completions/mean_length': 120.1875, 'completions/min_length': 39.5, 'completions/max_length': 164.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 120.1875, 'completions/min_terminated_length': 39.5, 'completions/max_terminated_length': 164.0, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.3125, 'rewards/reflect_reward/std': 0.8152145743370056, 'rewards/reasoning_length_reward/mean': 0.8239583373069763, 'rewards/reasoning_length_reward/std': 0.254335455596447, 'reward': 1.3210417032241821, 'reward_std': 0.4356700927019119, 'kl': 0.7578125, 'kl_visual': 0.014678955078125, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 22:17:57 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:17:57 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:17:57 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:17:57 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:17:57 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:17:57 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:17:57 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:17:57 [block_pool.py:264] Successfully reset prefix cache
Failed to cast start_time: 01:20, set to 0.
Failed to cast end_time: 01:50, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to cast start_time: random, set to 0.
Failed to cast end_time: random, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0062, 'grad_norm': 12.620016098022461, 'learning_rate': 9.9971222994377e-07, 'num_tokens': 8416213.0, 'completions/mean_length': 108.5, 'completions/min_length': 42.5, 'completions/max_length': 164.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 108.5, 'completions/min_terminated_length': 42.5, 'completions/max_terminated_length': 164.5, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.625, 'rewards/reflect_reward/std': 0.6094194948673248, 'rewards/reasoning_length_reward/mean': 0.9107639193534851, 'rewards/reasoning_length_reward/std': 0.164938323199749, 'reward': 1.4946527481079102, 'reward_std': 0.3001118004322052, 'kl': 1.21875, 'kl_visual': 0.012451171875, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 22:19:15 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:19:15 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:19:15 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:19:15 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:19:15 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:19:15 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:19:15 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:19:15 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0024, 'grad_norm': 9.13593864440918, 'learning_rate': 9.997014741774864e-07, 'num_tokens': 8582003.0, 'completions/mean_length': 115.1875, 'completions/min_length': 41.5, 'completions/max_length': 168.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 115.1875, 'completions/min_terminated_length': 41.5, 'completions/max_terminated_length': 168.0, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.625, 'rewards/reflect_reward/std': 0.5487886220216751, 'rewards/reasoning_length_reward/mean': 0.9399305582046509, 'rewards/reasoning_length_reward/std': 0.10849197208881378, 'reward': 1.500486135482788, 'reward_std': 0.2711547315120697, 'kl': 0.4609375, 'kl_visual': 0.012451171875, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 22:21:01 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:21:01 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:21:01 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:21:01 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:21:01 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:21:01 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:21:01 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:21:01 [block_pool.py:264] Successfully reset prefix cache
Failed to cast start_time: 8.3s, set to 0.
Failed to cast end_time: 1300.67s, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
Failed to cast start_time: 0.0s, set to 0.
Failed to cast end_time: 1.4s, set to 0xffff.
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0032, 'grad_norm': 7.6845903396606445, 'learning_rate': 9.996905211369745e-07, 'num_tokens': 8750103.0, 'completions/mean_length': 137.8125, 'completions/min_length': 32.0, 'completions/max_length': 248.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 137.8125, 'completions/min_terminated_length': 32.0, 'completions/max_terminated_length': 248.0, 'rewards/multiturn_format_reward/mean': 0.9375, 'rewards/multiturn_format_reward/std': 0.1767766922712326, 'rewards/reflect_reward/mean': 0.375, 'rewards/reflect_reward/std': 0.7315178513526917, 'rewards/reasoning_length_reward/mean': 0.9270833432674408, 'rewards/reasoning_length_reward/std': 0.17504514008760452, 'reward': 1.3104167580604553, 'reward_std': 0.3967115134000778, 'kl': 0.6357421875, 'kl_visual': 0.010162353515625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 22:21:57 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:21:57 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:21:57 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:21:57 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:21:57 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:21:57 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:21:57 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:21:57 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0009, 'grad_norm': 7.092909812927246, 'learning_rate': 9.996793708265585e-07, 'num_tokens': 8882984.0, 'completions/mean_length': 163.3125, 'completions/min_length': 115.0, 'completions/max_length': 236.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 163.3125, 'completions/min_terminated_length': 115.0, 'completions/max_terminated_length': 236.0, 'rewards/multiturn_format_reward/mean': 1.0, 'rewards/multiturn_format_reward/std': 0.0, 'rewards/reflect_reward/mean': 0.6875, 'rewards/reflect_reward/std': 0.6396867483854294, 'rewards/reasoning_length_reward/mean': 0.9395833611488342, 'rewards/reasoning_length_reward/std': 0.07083681225776672, 'reward': 1.5316666960716248, 'reward_std': 0.31543048471212387, 'kl': 0.1669921875, 'kl_visual': 0.0091400146484375, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
INFO 02-02 22:22:54 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:22:54 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:22:54 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:22:54 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:22:54 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:22:54 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:22:54 [block_pool.py:264] Successfully reset prefix cache
INFO 02-02 22:22:54 [block_pool.py:264] Successfully reset prefix cache
Invalidate trace cache @ step 365: expected module 2, but got module 365
Invalidate trace cache @ step 365: expected module 2, but got module 365
{'loss': 0.0011, 'grad_norm': 10.164613723754883, 'learning_rate': 9.996680232506403e-07, 'num_tokens': 9011858.0, 'completions/mean_length': 152.1875, 'completions/min_length': 61.0, 'completions/max_length': 229.5, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 152.1875, 'completions/min_terminated_length': 61.0, 'completions/max_terminated_length': 229.5, 'rewards/multiturn_format_reward/mean': 0.875, 'rewards/multiturn_format_reward/std': 0.2314550280570984, 'rewards/reflect_reward/mean': 0.8125, 'rewards/reflect_reward/std': 0.25877460837364197, 'rewards/reasoning_length_reward/mean': 0.9281250238418579, 'rewards/reasoning_length_reward/std': 0.12730705738067627, 'reward': 1.4668750762939453, 'reward_std': 0.35327192675322294, 'kl': 0.20458984375, 'kl_visual': 0.0102081298828125, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
DEBUG: Buffer S1 len: 8
DEBUG: Buffer S2 len: 8
DEBUG: Buffer S2 len: 8
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mcheck600_v_1_video-r1_stage2_cyt[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20260202_211325-gwda6z5m/logs[0m
